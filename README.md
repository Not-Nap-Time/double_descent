# double_descent

ёРезультаты

1. Графики 
   - dataset_size = 5: очень низкий test loss за счёт запоминания всех 5 точек.  
   - dataset_size = 30, 100, 1000: самое высоке значение loss — модель начинает обобщать, а не просто запоминать
   - dataset_size = 5000: loss снова падает, т.к. моделе уже достаточно данных, чтобы обобщать

2. Распределение признаков и скрытого слоя  
   - dataset_size = 5: признаки и скрытые векторы образуют чёткий, пятиугольник — ровно 5 точек, так как модель запомнила каждый пример.  
   - dataset_size = 30, 100, 1000: плотность точек возрастает, кластеры признаков становятся более размытими что соответствует похоже на начало обобщения, а не запоминания.  
   - dataset_size = 5000: плотное круговое облако признаков и симметричный пентагон скрытых векторов с пятью явно выраженными направлениями — признак успешного обобщения на больших данных.  

3. Проблемы:
   - Было деление на 0, но это легко исправляется за счет eps в знаменатиле
